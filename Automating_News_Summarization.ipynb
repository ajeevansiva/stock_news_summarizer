{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajeevansiva/stock_news_summarizer/blob/main/Automating_News_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "6FCAgufs-S4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, pipeline, AutoModelForSeq2SeqLM\n",
        "from transformers import LlamaForCausalLM\n",
        "# Specify the name of the pre-trained model\n",
        "model_name = 'daryl149/llama-2-7b-chat-hf'\n",
        "\n",
        "\n",
        "# Load the pre-trained model and its tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = LlamaForCausalLM.from_pretrained(pretrained_model_name_or_path='daryl149/llama-2-7b-chat-hf', load_in_8bit=True, device_map={'': 0},)"
      ],
      "metadata": {
        "id": "mh5YJD-L-ThF",
        "outputId": "0457168e-a0d6-4a1b-bccd-67a4e8e24f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "f4605582f61542f2b62f6331fca7c3e6",
            "48fff7e2ed7d44bdb8d1e43b807f5889",
            "cda7e0b94920455a93be52210b327776",
            "11d20f73d62948928aa907f6dc7a4913",
            "d02a0e882e124e61b304c5bfee73672c",
            "a04a73a8d9fd4490a3ffad5a9239c688",
            "f7b772118523433fbda3106fb5042573",
            "c4f29c1fc7574b1ba0f76dbea2fdf8f7",
            "bf1fc6b2496640c389ed62411edcb44f",
            "aa8525ec4fec400aaea0b9c93ff95beb",
            "79a59b88ff5a4d72b5f66adb3fecbb8e"
          ]
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4605582f61542f2b62f6331fca7c3e6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8N0VlxA5Moo",
        "outputId": "621c41d4-5a6e-4e64-bfb0-d1ce461da522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News headlines:\n",
            "- \n",
            "- \n",
            "- Last Updated : 2024-03-31 13:38:00\n",
            "- Daily FT\n",
            "- Sunday Times\n",
            "- Mirror Edu\n",
            "- Tamil Mirror\n",
            "- Lankadeepa\n",
            "- Middleast Lankadeepa\n",
            "- Ada\n",
            "- Deshaya\n",
            "- Life Online\n",
            "- Hi Online\n",
            "- HitAd\n",
            "- TimesJobs\n",
            "- E-Paper\n",
            "- Home delivery\n",
            "- Advertise with us\n",
            "- Mobile Apps\n",
            "- feedback\n",
            "- Archive\n",
            "- Print Ads\n",
            "- Sun, 31 Mar 2024 Today's Paper\n",
            "- 29 March 2024 03:14 pm\n",
            "  - 11      - {{hitsCtrl.values.hits}}\n",
            "- By Ranjith Rajapakshe\n",
            "- Ratnapura, March 29 (Daily Mirror)- An Indian tourist who fell down a more than 100 metre precipice at the Ehela Kanuwa, Ratnapura-Sri Pada route in the early hours of this morning was rescued by a team from the Maskeliya Police Special Task Force (STF) camp.\n",
            "- Police said the tourist Bharath Chandradas (25) from Mumbai Maharastra had been trekking to Sri Pada along the Ratnapura route with several others when he fell off the protective fence down the precipice at about 5.00 am today.\n",
            "- On information from the Udamaluwa police post, the STF rushed to the scene and rescued the tourist and provided first aid.\n",
            "- Later, he was carried to Nallathanniya and from there admitted to hospital.\n",
            "- PC 76216 Pathmasiri, PC 99695 Prathish and PC 102687 Ajith of the STF carried out the rescue operation.\n",
            "- Ram Friday, 29 March 2024 03:28 PM\n",
            "- Lucky man thanks to emergency services\n",
            "- Reply\n",
            "- Joshua Friday, 29 March 2024 03:40 PM\n",
            "- Well done STF.\n",
            "- Reply\n",
            "- Rohan Friday, 29 March 2024 04:46 PM\n",
            "- Well done guys. Thanks for the heroic rescue efforts.\n",
            "- Reply\n",
            "- KEEP AWAY FROM PROTECTIVE FENCE Friday, 29 March 2024 05:00 PM\n",
            "- What a MIRACLE. can the authorities please put up a few boards on the way up and also along the fence, asking visitors to KEEP AWAY FROM PROTECTIVE FENCE.\n",
            "- Reply\n",
            "- Suhada malli Friday, 29 March 2024 05:58 PM\n",
            "- Thank You Daily Mirror and Police for publishing positive stories of this nature about the good work our police including STF does for the nation. Due to divisive politics coming from the British days we sri Lankans get an overload of negative news in our media. subjects such as corruptions happens even in very developed countries such as Canada and USA. Difference is they deal with it with a lot of shame and don't make it an over rated achievement.\n",
            "- Reply\n",
            "- Think about it Friday, 29 March 2024 07:43 PM\n",
            "- If similar event has happened to a Sri Lankan in India, Indian rescue team would never have rushed to help the Sri Lankan. They wold have come after 24 hours to collect the Sri Lankan, dead or alive.\n",
            "- Reply\n",
            "- Practice Loving Kindness if No Evidence  Saturday, 30 March 2024 06:17 AM\n",
            "- Unnecessarily instigating trouble here! Please share an incident where they took that long to rescue someone. If not, just practice loving kindness in your spare time instead of making this world a more hatred place.\n",
            "- \n",
            "- The scale of Corruption  Saturday, 30 March 2024 06:26 AM\n",
            "- @ Suhada malli. Yes, all countries have some kind of corruption. However the scale of it can’t beat SL. Remember, these guys owe over US$50 Billion in loans over the years and still seek new loans by the month. In every project they do, either corruption or mismanagement of money is the norm. There are sooo many more cases not mentioned as it’s hard to find evidence. Either you are one of them or from the elite crowd who is not feeling the misery of the average person in SL is going through now because of years of corruption and mismanagement.\n",
            "- Reply\n",
            "- nihal jayaweera Saturday, 30 March 2024 08:37 AM\n",
            "- As usual  this guy would have tried some stunts ........ to showoff, if not never heard of this type of falls by any Sri Lankan ... \n",
            "nj\n",
            "- Reply\n",
            "- Seqi Saturday, 30 March 2024 09:42 AM\n",
            "- Think about it.... in your dreams, nasty little bugger.\n",
            "- Reply\n",
            "- wsw Saturday, 30 March 2024 11:47 AM\n",
            "- Well done STF, we are always proud of our special forces whether in combat or rescue.\n",
            "- Reply\n",
            "- \n",
            "- \n",
            "- Reply To:\n",
            "- Name - Reply Comment\n",
            "- Though the Government imposed VAT (Value Added Tax) on vegetables and other e\n",
            "- Saving energy has become more of a responsibility than a habit in today’s c\n",
            "- In the coming days, Muslims across the world will welcome the Holy Month of R\n",
            "- As of February 2024, Sri Lanka lost another 38 elephants as a result of the H\n",
            "- 1\n",
            "- 2\n",
            "- 3\n",
            "- 4\n",
            "- 5\n",
            "- 6\n",
            "- \n",
            "- \n",
            "- \n",
            "- 29 Mar 2024 \n",
            "  - 5      - 984\n",
            "- 29 Mar 2024 \n",
            "  - 0      - 136\n",
            "- 29 Mar 2024 \n",
            "  - 17      - 12200\n",
            "- 29 Mar 2024 \n",
            "  - 0      - 135\n",
            "- More\n",
            "- 30 Mar 2024\n",
            "- 30 Mar 2024\n",
            "- 30 Mar 2024\n",
            "- 30 Mar 2024\n",
            "- 29 Mar 2024\n",
            "- 29 Mar 2024\n",
            "- 29 Mar 2024\n",
            "- 29 Mar 2024\n",
            "- More\n",
            "- Editorial :\n",
            "- +94 0112 479 356\n",
            "- dmonlinelk@gmail.com\n",
            "- Technical :\n",
            "- +94 011 538 3437\n",
            "- helpdesk@wijeya.lk\n",
            "- webadsupport@wijeya.lk\n",
            "- Marketing :\n",
            "- +94 011 247 9540\n",
            "- +94 011 247 9873\n",
            "- Web Advertising Inquiry :\n",
            "- Dilan : +94 77 372 7288\n",
            "- Print Advertising :\n",
            "- Trevin : +94 71 192 5009\n",
            "- trevine@wijeya.lk\n",
            "- Direct : +94 011 2479519\n",
            "- General : +94 011 2479540\n",
            "- All the content on this website is copyright protected and can be reproduced only by giving the due courtesy to 'dailymirror.lk' Copyright © 2004 Wijeya Newspapers Ltd.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "def scrape_news(url):\n",
        "    try:\n",
        "        # Define headers\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"\n",
        "        }\n",
        "\n",
        "        # Send a GET request to the URL with headers\n",
        "        r = requests.get(url, headers=headers)\n",
        "        r.raise_for_status()  # Raise an error for bad status codes\n",
        "\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "        # Find all paragraphs and filter out messages\n",
        "        paragraphs = soup.find_all('p')\n",
        "        filtered_paragraphs = [p.text.strip() for p in paragraphs if \"Thank you for your patience.\" not in p.text.strip()]\n",
        "\n",
        "        return filtered_paragraphs\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "url = \"https://www.dailymirror.lk/breaking-news/Tourist-rescued-after-falling-down-Sri-Pada-precipice/108-279832\" #Edit url here\n",
        "\n",
        "news = scrape_news(url)\n",
        "newsString = ' '.join(news)\n",
        "if news:\n",
        "    print(\"News headlines:\")\n",
        "    for headline in news:\n",
        "        print(\"-\", headline)\n",
        "else:\n",
        "    print(\"No news scraped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c4cM7v6VQKR",
        "outputId": "c0767883-7d8b-4f93-c35f-283a588d8f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': 'Bharath Chandradas (25) from Mumbai Maharastra had been trekking to Sri Pada along the Ratnapura route with several others when he fell off the protective fence down the precipice at about 5.00 am today. On information from the Udamaluwa police post, the STF rushed to the scene and rescued the tourist and provided first aid. Later, he was carried to Nallathanniya and from there admitted to hospital.'}]\n",
            "<class 'list'>\n",
            "Summary:\n",
            "Bharath Chandradas (25) from Mumbai Maharastra had been trekking to Sri Pada along the Ratnapura route with several others when he fell off the protective fence down the precipice at about 5.00 am today. On information from the Udamaluwa police post, the STF rushed to the scene and rescued the tourist and provided first aid. Later, he was carried to Nallathanniya and from there admitted to hospital.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def summarize_text(input_text, model_name=\"Ajeevan123/NewsSummarization\", max_chunk_len=510):\n",
        "    summarization_pipeline = pipeline(\"summarization\", model=model_name, tokenizer=model_name)\n",
        "\n",
        "\n",
        "    summarized_output = summarization_pipeline(input_text, max_length=510, min_length=40, do_sample=False)\n",
        "\n",
        "    return summarized_output\n",
        "\n",
        "# Example input text\n",
        "input_text = newsString\n",
        "\n",
        "# Summarize the input text\n",
        "summary = summarize_text(input_text)\n",
        "print(summary)\n",
        "sr = str(summary[0]['summary_text'])\n",
        "print(type(summary))\n",
        "# Print the summary\n",
        "print(\"Summary:\")\n",
        "print(sr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHVdz9_4Onfl",
        "outputId": "e593d599-f7be-412f-a98d-4b1df5f25273"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = sentiment(sr)\n",
        "summary_sentiment_info = \"Based on the description and the sentiment analysis answer the below prompts: Summary: \" + sr + \", Sentiment: \" + result[0]['label'] + \", Score: \" + str(result[0]['score'])"
      ],
      "metadata": {
        "id": "owdtEOMGObs-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_sentiment_info = \"Based on the description and the sentiment analysis answer the below prompts: Summary: \" + sr + \", Sentiment: \" + result[0]['label'] + \", Score: \" + str(result[0]['score'])\n",
        "print(summary_sentiment_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz-gaKqpnEW4",
        "outputId": "e4e61b17-b12a-42d1-851c-84725ede0bee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the description and the sentiment analysis answer the below prompts: Summary: Bharath Chandradas (25) from Mumbai Maharastra had been trekking to Sri Pada along the Ratnapura route with several others when he fell off the protective fence down the precipice at about 5.00 am today. On information from the Udamaluwa police post, the STF rushed to the scene and rescued the tourist and provided first aid. Later, he was carried to Nallathanniya and from there admitted to hospital., Sentiment: NEGATIVE, Score: 0.9753184914588928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "ujM7LQvvrSPC",
        "outputId": "499c14fe-00c9-44d7-e4d1-cb9424fadc60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User's prompt\n",
        "user_prompt = \"From which country is this person\"\n",
        "\n",
        "\n",
        "# Combine user prompt and summary sentiment info\n",
        "instruction = f\"### Instruction:\\n{summary_sentiment_info}\\n{user_prompt}\\n### Response:\\n\"\n",
        "\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "\n",
        "# Generate the response\n",
        "result = pipe(instruction)\n",
        "\n",
        "response = result[0]['generated_text'][len(instruction):]\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "dpyeemLIu3AC",
        "outputId": "bd92ab59-35cc-4726-e6bc-378a3b8c99a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the information provided in the prompt, the person's country of origin is India, specifically the state of Maharashtra. Therefore, the answer to the prompt is:\n",
            "India\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4605582f61542f2b62f6331fca7c3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48fff7e2ed7d44bdb8d1e43b807f5889",
              "IPY_MODEL_cda7e0b94920455a93be52210b327776",
              "IPY_MODEL_11d20f73d62948928aa907f6dc7a4913"
            ],
            "layout": "IPY_MODEL_d02a0e882e124e61b304c5bfee73672c"
          }
        },
        "48fff7e2ed7d44bdb8d1e43b807f5889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04a73a8d9fd4490a3ffad5a9239c688",
            "placeholder": "​",
            "style": "IPY_MODEL_f7b772118523433fbda3106fb5042573",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cda7e0b94920455a93be52210b327776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4f29c1fc7574b1ba0f76dbea2fdf8f7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf1fc6b2496640c389ed62411edcb44f",
            "value": 2
          }
        },
        "11d20f73d62948928aa907f6dc7a4913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8525ec4fec400aaea0b9c93ff95beb",
            "placeholder": "​",
            "style": "IPY_MODEL_79a59b88ff5a4d72b5f66adb3fecbb8e",
            "value": " 2/2 [01:07&lt;00:00, 30.54s/it]"
          }
        },
        "d02a0e882e124e61b304c5bfee73672c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04a73a8d9fd4490a3ffad5a9239c688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b772118523433fbda3106fb5042573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f29c1fc7574b1ba0f76dbea2fdf8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1fc6b2496640c389ed62411edcb44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa8525ec4fec400aaea0b9c93ff95beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a59b88ff5a4d72b5f66adb3fecbb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}